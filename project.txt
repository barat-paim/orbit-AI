# Orbit-VI Backend Pipeline Documentation

Let me break down how `full_test.py` works:

1. **Test Setup & Structure**
```python
# The test uses TestMetrics class to track:
- Query success/failure
- API call success/failure
- Data validation success/failure
- Visualization success/failure
- Processing times
- Error messages
```

2. **Data Flow Steps**
```python
a. Query Processing:
   - Takes natural language query
   - Uses QueryProcessor to generate API requirements
   - Validates requirements format

b. API Integration:
   - Converts requirements to Ergast API URL
   - Makes HTTP request
   - Gets XML response
   - Converts XML to DataFrame using xml_to_dataframe

c. Data Validation:
   - Validates DataFrame structure
   - Checks required columns
   - Ensures data types

d. Visualization:
   - Uses generate_code() from generate.py
   - Passes DataFrame and query
   - Gets visualization code
   - Executes code safely
   - Returns base64 encoded image
```

3. **Test Cases**
```python
test_cases = [
    "Show me Max Verstappen's points progression throughout the 2023 season",
    "Compare qualifying times between Hamilton and Verstappen in 2023",
    "Plot the number of podiums for each constructor in 2023",
    # ... more test cases ...
]
```

4. **Parallel Processing**
```python
- Processes test cases in batches (batch_size = 2)
- Uses asyncio for concurrent execution
- Handles rate limits for API and GPT-4O
```

5. **Error Handling & Metrics**
```python
- Records success/failure at each stage
- Tracks processing time
- Provides detailed error messages
- Generates test summary with statistics
```

## Query Processing Stage

### 1. Entry Point & Flow

Q: Which endpoint/route in the backend first receives the user's natural language query?
A: The query is first received by the /api/query endpoint in the FastAPI backend. This is defined in app/api/routes.py.

Q: What is the first class that handles this query?
A: The QueryProcessor class in app/query/processor.py is the first class that handles the raw query.

Q: How is the query passed from the API route to the query processor?
A: The query is passed as a string to the QueryProcessor.process_query() method, which is an async method that handles the initial processing.

### 2. Query Processor Internals

Q: What is the main class responsible for processing queries?
A: The QueryProcessor class in app/query/processor.py is the main class responsible for processing queries.

Q: What are the key methods in the QueryProcessor class?
A: The key methods are:
- process_query(): Main entry point that processes the raw query
- _generate_requirements(): Uses GPT-4O to generate structured requirements
- _validate_requirements(): Validates the generated requirements
- _extract_requirements(): Extracts API parameters from the model's response

Q: How does the processor convert natural language to structured requirements?
A: The processor uses GPT-4O to analyze the natural language query and generate structured requirements. It sends a prompt that includes the query and expects a response in a specific format that includes the API endpoint and parameters needed.

Q: What role does GPT-4O play in query processing?
A: GPT-4O analyzes the natural language query to:
1. Understand the user's intent
2. Determine which F1 API endpoint is needed
3. Extract relevant parameters (season, driver, constructor, etc.)
4. Generate structured requirements in a format the pipeline can use

### 3. Input/Output Understanding

Q: What is the exact format of input the query processor expects?
A: The query processor expects a simple string containing the natural language query (e.g., "Show me Max Verstappen's points in 2023").

Q: What is the structure of the DataRequirements object it outputs?
A: The DataRequirements object contains:
- endpoint: str (e.g., "/api/f1/drivers")
- params: Dict[str, Any] (e.g., {"season": "2023", "driver": "max_verstappen"})
- source: str (type of data being requested)

Q: How are API parameters extracted from the natural language query?
A: GPT-4O extracts parameters by:
1. Identifying key entities (drivers, teams, seasons)
2. Mapping them to API parameter names
3. Formatting them according to API requirements
4. Including them in the structured output

Q: What validation happens on the generated requirements?
A: The _validate_requirements() method checks:
1. Required fields are present
2. Endpoint is valid
3. Parameters match endpoint expectations
4. Values are in correct format

## API Integration Stage

### 1. Data Pipeline

Q: How does the DataPipeline class convert QueryProcessor output to API calls?
A: The DataPipeline:
1. Takes DataRequirements object
2. Constructs the full API URL
3. Formats parameters
4. Makes the HTTP request to Ergast API

Q: What transformations happen to the requirements before making API calls?
A: The requirements undergo:
1. URL encoding of parameters
2. Season parameter moved to URL path
3. None values filtered out
4. Parameter name formatting

Q: How are different F1 API endpoints handled?
A: Each endpoint has specific handling in:
1. Parameter validation
2. Response parsing
3. Data transformation
4. Error handling

Q: What error handling exists in the pipeline?
A: The pipeline handles:
1. Network timeouts with retries
2. Invalid API responses
3. Missing or malformed data
4. Rate limiting
5. XML parsing errors

### 2. API Response Handling

Q: How is the XML response from Ergast API processed?
A: The XML response is processed by:
1. Parsing with xml.etree.ElementTree
2. Extracting relevant data nodes
3. Converting to structured format
4. Creating pandas DataFrame

Q: What is the role of the xml_to_dataframe function?
A: This function:
1. Parses XML response
2. Extracts data based on endpoint
3. Handles different data structures
4. Creates consistent DataFrame format

Q: What data validation happens after receiving API responses?
A: The response is validated for:
1. Required fields presence
2. Data type correctness
3. Value ranges
4. Consistency checks

Q: How are different types of responses (drivers, races, etc.) handled?
A: Each response type has:
1. Specific parsing logic
2. Custom validation rules
3. Unique data transformations
4. Type-specific error handling

## Visualization Generation Stage

### 1. Generator Architecture

Q: What is the difference between generate.py and generator_2.py?
A: 
- generate.py: Original implementation that uses DataFrame intermediary
- generator_2.py: Simplified version that works directly with XML and focuses on visualization

Q: How does the code generation process work?
A: The process:
1. Takes data and query
2. Creates prompt for GPT-4O
3. Gets Python code response
4. Executes code safely
5. Returns visualization

Q: What role does GPT-4O play in visualization generation?
A: GPT-4O:
1. Analyzes query intent
2. Generates appropriate visualization code
3. Handles data preprocessing
4. Creates matplotlib/seaborn plots

Q: How is the generated code executed safely?
A: Code is executed:
1. In isolated namespace
2. With limited imports
3. With timeout protection
4. With error catching

### 2. Data Flow

Q: What formats of data can the generator accept?
A: The generator accepts:
1. Pandas DataFrames
2. Raw XML data
3. Structured dictionaries
4. JSON data

Q: How is the visualization prompt constructed?
A: The prompt includes:
1. User's query
2. Data sample/structure
3. Required visualization type
4. Available libraries
5. Output format requirements

Q: What happens if the generated code fails?
A: The system:
1. Catches the error
2. Logs failure details
3. Returns error message
4. Optionally retries with modified prompt

Q: How are the visualizations returned to the frontend?
A: Visualizations are:
1. Saved as PNG
2. Encoded in base64
3. Included in response JSON
4. Sent with metadata

## Testing & Validation

### 1. Test Structure

Q: How is the full pipeline tested end-to-end?
A: Testing includes:
1. Query processing
2. API calls
3. Data validation
4. Visualization generation
5. Error handling

Q: What metrics are tracked during testing?
A: Tracked metrics:
1. Query success rate
2. API call success
3. Validation results
4. Visualization success
5. Processing times

Q: How are different types of errors handled and logged?
A: Errors are:
1. Categorized by type
2. Logged with context
3. Tracked in metrics
4. Reported in summary

Q: What assertions validate correct pipeline operation?
A: Assertions check:
1. Query processing success
2. API response validity
3. Data transformation
4. Visualization generation

### 2. Performance & Reliability

Q: How are API timeouts and retries handled?
A: The system:
1. Sets appropriate timeouts
2. Implements retry logic
3. Backs off between retries
4. Logs retry attempts

Q: What batch processing happens for multiple queries?
A: Batch processing:
1. Groups queries
2. Processes in parallel
3. Manages rate limits
4. Aggregates results

Q: How is parallel processing implemented?
A: Using:
1. asyncio for async/await
2. Task batching
3. Concurrent API calls
4. Resource management

Q: What performance metrics are important?
A: Key metrics:
1. Query processing time
2. API response time
3. Visualization generation time
4. Overall latency
5. Success rates

## Practical Scenarios

### 1. Debug & Troubleshoot

Q: If a query fails, where do you look first?
A: Check:
1. Query processor logs
2. API response status
3. Error messages
4. Generated code

Q: How do you identify if the failure is in query processing, API call, or visualization?
A: Look at:
1. Stage-specific logs
2. Error types
3. Success flags
4. Component metrics

Q: What logs are available for debugging?
A: Available logs:
1. Query processing
2. API calls
3. Data validation
4. Code generation
5. Execution results

Q: How do you test individual components?
A: Components can be tested:
1. Using unit tests
2. With mock data
3. In isolation
4. With specific inputs

### 2. Extension & Modification

Q: How would you add support for a new F1 API endpoint?
A: Steps:
1. Update DataRequirements
2. Add endpoint validation
3. Create response parser
4. Update visualization logic

Q: How would you modify the visualization generation?
A: Options:
1. Update prompt templates
2. Add new visualization types
3. Modify code generation
4. Enhance error handling

Q: What's involved in adding new query capabilities?
A: Process:
1. Update query processor
2. Enhance GPT-4O prompts
3. Add new requirements
4. Update validation

Q: How would you improve error handling?
A: Improvements:
1. Add more specific error types
2. Enhance retry logic
3. Improve error messages
4. Add recovery strategies 